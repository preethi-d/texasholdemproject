%%%% ijcai18.tex

\typeout{IJCAI-18 Instructions for Authors}

% These are the instructions for authors for IJCAI-18.
% They are the same as the ones for IJCAI-11 with superficical wording
%   changes only.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai18.sty is the style file for IJCAI-18 (same as ijcai08.sty).
\usepackage{ijcai18}

% Use the postscript times font!
\usepackage{mathptmx}
\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}


% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Poker Project - Team 07}


% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)

\author{
Arielyte Tsen Chung Ming, Devarajan Preethi, James Pang Mun Wai, Lee Yi Wei Joel, Yip Seng Yuen
\\ 
National University of Singapore\\
%
chungming.tsen@u.nus.edu, e0203237@u.nus.edu, jamespang@nus.edu, lywjoel@u.nus.edu, yip@u.nus.edu
}
% If your authors do not fit in the default space, you can increase it 
% by uncommenting the following (adjust the "2.5in" size to make it fit
% properly)
% \setlength\titlebox{2.5in}

\begin{document}

\maketitle

\section{Introduction}

The game of poker has long been a field of interest for artificial intelligence (AI) researchers. This is not surprising as developing an AI poker agent capable of competing with humans at the highest level is challenging, given that poker is a game that forces players to make decisions with incomplete and imperfect information. This paper talks about the steps we took in designing an AI Poker Player agent in Heads Up Limit Texas Hold'em. An agent subjected to reinforcement learning must learn to interact with the environment in order to maximize its reward. Reinforcement learning was chosen as a way to get the best possible action based on the current state.

The problem with Limit Texas Hold'em is that there is no input or output training data sets available for the agent to gather feedback from. Hence, the only way an agent can learn is by trial and error based on feedback from its own actions and experiences. A reward function is created, where actions that led to positive outcomes are rewarded, and actions that led to negative outcomes are penalized, with the goal of maximizing its reward. The basis for this project is to design a reward function that is good enough for the agent to master poker. In a game of poker, the agent does not have a complete model of the environment, nor does it know the states that its actions will lead to. Thus, we chose a Q-learning agent, which compares the expected utilities of the remaining choices without the need to know the outcomes nor the model of the environment~\cite{russell-norvig:Modern}, as it fits the scenario of a poker game.

\section{Pre-Flop Hand Strength}

To begin with, we wanted to decide how the agent would determine the strength of its hand, based only on the pre-flop round. Due to the limited amount of information that we can manipulate during the pre-flop round, the strength of a hand, $HS$, at pre-flop is determined by the probability of winning, $Pr(Win)$, based on the prior knowledge of the two hole cards currently in hand. 

To estimate $HS$, we simulated 10,000 games for each possible combination of starting hand. The total combination of starting hands is  13 + ${13 \choose 2}$ = 91, obtained by summing up the combinations of pocket pairs and the combinations of possible hands, ignoring the suits. For each game, we first pick the two starting cards for the agent, followed by randomly picking two starting cards for the opponent and five community cards. Both players' hands are then revealed and the game result determined as a win or a loss for the agent.

We then calculate $Pr(Win)$ using the formula:
\begin{displaymath}
Pr(Win)= \frac{\# \text{ } of \text{ } wins}{Total \text{ }games \text{ } played}
\end{displaymath}
Where the total games played is fixed at 10,000 in our case. The results of our simulation are seen in Figure \ref{fig:1}.
\begin{figure}
  \includegraphics[width=\linewidth]{WinningProb.PNG}
  \caption{Estimated winning probabilities with starting hands}
  \label{fig:1}
\end{figure}

At every pre-flop street, the agent chooses an action to be performed based on the starting hand's estimated probabilities of winning, which are:
\begin{displaymath}
  \left.
  \begin{array}{l}
    raise \text{: } Pr(Win) > k \\
    \\
    call \text{: } Pr(Win) > j \\
    \\
    fold \text{: } Pr(Win) \leq j
  \end{array}
  \right\rbrace \quad \text{where } 0 < j < k \leq 1
\end{displaymath}
Where $j$ and $k$ are pre-determined thresholds set for the agent.

\section{Post-Flop Rounds}

In subsequent post-flop rounds, reinforcement learning is employed. Specifically, the technique of Q-learning - which was described in the introduction - was used to train our agent.

In Q-learning, we maintain a table of states and actions as input for the agent. Each state has a Q-value that corresponds to each action. An illustration of it can be seen in Table 1.

\begin{table}[h!]
  \begin{center}
	\begin{tabular}{ c|c|c|c }
	\hline
	\multirow{2}{*}{\textbf{State}}&\multicolumn{3}{|c}{\textbf{Action}}\\
	\cline{2-4}
	& $fold$ & $call$ & $raise$\\ 
	\hline
	1\\
	2\\ 
	3\\ 
	$\cdots$\\
	S\\
	\hline
	\end{tabular}
	\caption{Q-learning Training}
    \label{tab:table1}
  \end{center}
\end{table}
After each training round, the Q-value of each state is calculated and updated based on the formula given below:
\begin{displaymath}
Q\left(s',a'\right)=Q\left(s,a\right)+\sum_{0}^{t}\lambda^{t}R_t\left(s,a\right)
\end{displaymath}
Where $t$ is the number of turns between the current move and the terminal node, $R_t$ is the reward for round $t$, $\lambda$ is the discount factor, $s$ is the state and $a$ is the action.

\begin{displaymath}
  R_t=
  \left\lbrace
  \begin{array}{l}
    +\frac{pot}{2}\quad\text{if win,} \\
    \\
    -\frac{pot}{2}\quad\text{otherwise}
  \end{array}
  \right.
\end{displaymath}
\begin{displaymath}
  \lambda=\text{discount rate for future reward}
\end{displaymath}

Additionally, we applied the technique of experience replay to achieve more efficient use of previous experiences. We store the agent's experiences based on the formula
\begin{displaymath}
e_t=\left(s_t,a_t,R_t,s_{t+1}\right)
\end{displaymath}
The agent stores the data discovered for each round in a table, and reinforcement learning takes place based on random sampling from the table. This reduces the amount of experience required to learn, replacing it with more computation and memory which are cheaper resources than the agent's continuous interactions with the environment~\cite{sqas:replay}.

\subsection{$\epsilon$-Greedy Algorithm}

At every turn, with a probability of $\epsilon$, a random action is chosen to be performed, otherwise an action with the best expected reward is chosen.

The value of $\epsilon$ will slowly decrease as the agent acquires more training. A relatively large initial value ensures that all possible paths will be explored before the agent settles into a sub-optimal pattern. The $i$-th $State$ and possible $Actions$ for the $\epsilon$-Greedy Algorithm is
\begin{displaymath}
State_i = \{ EHS_i \text{, } S_i \text{, }P_i\text{, }\#OR_i\text{, }\#SR_i\text{, }OPS_i\}
\end{displaymath}
\begin{displaymath}
Actions = \{ fold\text{, }call\text{, }raise \}
\end{displaymath}
Where

\begin{description}[style=multiline,leftmargin=10mm]
\item [\emph{EHS}]refers to the current Expected Hand Strength of a given player. $EHS$ is grouped in increments of 0.01. More details can be found in Section 4.1.
\item [\emph{S}]refers to the current Street that the game is in, which is the start of each new round. There are three streets - Flop, Turn and River.
\item [\emph{P}]refers to the Pot Size, which is the total amount in the player's bet. $P$ in a game ranges from 0 to 680, but by grouping it terms of number of big blinds, we get a range of 0 to 34.
\item [\emph{\#OR}]refers to the number of Opponent Raises per street. $OR$ is grouped into five different groups, i.e. from 0 to 4.
\item [\emph{\#SR}]refers to the number of Self Raises per street. $SR$ is grouped into five different groups, i.e. from 0 to 4.
\item [\emph{OPS}]refers to the Opponent Playing Style. $OPS$ is grouped into four categories. More details can be found in Section 4.3
\end{description}

Without the groupings, the total size of the state space will be very large and it would be infeasible to calculate all possible states. Therefore, we can apply abstraction by grouping some of the features in increments. For example, rather than considering all possible pot sizes between \$0 to \$680, we could instead just consider the increments of \$20 (which is the big blind amount), this will then reduce down our state space by a factor of 20 while not sacrificing the accuracy of the algorithm because the difference between a pot size of \$20 and a pot size of \$21 is very minor. The similar abstraction technique was used on the other features as well to reduce the complexity and cut down the size of the total state space to: 101 x 3 x 35 x 5 x 5 x 4 = 1,060,500 states

\subsection{Expected Hand Strength}

The Expected Hand Strength, $EHS$ is the probability of the current hand of a given player winning if the game reaches a showdown. It factors in all possible combinations of the opponents' hands, the remaining hidden board cards, and performing a comparison between the agent's hand and the hands in the enumeration to see which is better. The quality of the hand is then measured based on the number of times the hand turns out to be better. For our $\epsilon$-Greedy Algorithm, the $EHS$ is grouped in increments of 0.01. The remaining cards, $Rem$ is given by:
\begin{displaymath}
  Rem = \left[ \alpha \char`\\ \beta \right]^{5}
\end{displaymath}
Where $\alpha$ is the set of all cards in the deck, and $\beta$ is the set of all hole cards of a particular player. The formula to calculate the rank of each hand, $Rank(h)$ is:
\begin{displaymath}
  Rank(h) = max({\forall x \in [\beta \cup \Omega]^{5} : s(x)})
\end{displaymath}
Where $\Omega$ is the set of community cards.
Having $Rem$ and $Rank(h)$, it is now possible to calculate $HS$ through the formulas below:
\begin{displaymath}
  Ahead(h) = \# \left\lbrace \forall x \in Rem:s(x) > Rank(h) \right\rbrace
\end{displaymath}
\begin{displaymath}
  Tied(h) = \# \left\lbrace \forall x \in Rem:s(x) = Rank(h) \right\rbrace
\end{displaymath}
\begin{displaymath}
  Behind(h) = \# \left\lbrace \forall x \in Rem:s(x) < Rank(h) \right\rbrace
\end{displaymath}\\
Thus, the $EHS$ for player $h$ against 1 opponent is given by:
\begin{displaymath}
  EHS(h)= \frac{Ahead(h)+\frac{Tied(h)}{2}}{Ahead(h) + Tied(h) + Behind(h)}
\end{displaymath}

\noindent The above formulas used to derive the $EHS$ was referenced from Teofilo \textit{et al.}~\shortcite{trc:hs}. Note that the $EHS$ may be used at any round of the game. However, the time required to compute an accurate EHS exceeds the time constraint of 0.2s set by the project guidelines, as the number of iterations needed to compute it for a single hand at the pre-flop street is very high. This issue is addressed by using the Average Rank Strength technique which is explained in the next section.

\subsection{Average Rank Strength}

A technique developed by Teofilo \textit{et al.}~\shortcite{trc:ars} called Average Rank Strength ($ARS$), is used to improve the efficiency of $EHS$. $ARS$ consists of using the hand score to estimate the future outcome of the match, without having to generate all card combinations. This is simply done by storing the average $EHS$ of a hand for each score in three lookup tables, one for Flop, one for Turn and one for River. Since we are not considering suits, the number of possible scores is reduced. The pre-computation of a given score is as follows:
\begin{displaymath}
  ARS_{5}\left(C_{1}, C_{2}\right)=(\frac{\sum_{i}X_{i} \in [\alpha \char`\\ \beta]^{5}:Rank \left(X_{i} \cup \left \lbrace C_{1}, C_{2} \right \rbrace \right)}{\#[\alpha \char`\\ \beta]^{5}}
\end{displaymath}\\
Where $X_i$ is a distinct subset of size 5 of the deck except the pocket cards.

Thus, compared to $EHS$, $ARS$ had a three orders of magnitude faster response time when querying the lookup table, while also doing so with negligible error~\cite{trc:ars}. This is due to the fact that getting the EHS from the lookup table runs in constant time.

To find out the estimated $EHS$ for the three post-flop streets, we simulated 2,500,000 rounds each. Additionally, for each round of simulation, we ran the Monte Carlo sampling algorithm 500 times to obtain the $EHS$. The results are displayed below:

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|c}
      \textbf{Street} & \textbf{Number of Combinations} \\
      \hline
      Flop & 5133 \\
      Turn & 13,408 \\
      River & 17,470 \\
    \end{tabular}
    \caption{Result of $ARS$ Simulation}
    \label{tab:table2}
  \end{center}
\end{table}

\noindent The reason for the high number of simulations is that we want to sample as many score combinations as possible.

Based on the results from simulating 100,000 rounds, approximately 99.87\% of the scores can be found in the table. This goes to show that our three $ARS$ tables are highly reliable.

\subsection{Opponent Playing Styles}

According to Rupeneite~\shortcite{rupeneite:Reinforcement}, the playing style of an opponent can be classified into four categories. Each style is distinct, in that it describes the opponent's frequency of play and how the player bets. The four categories of playing styles are Loose/Passive, Loose/Aggressive, Tight/Passive and Tight/Aggressive. A brief description of each style is shown in Table 3 below:

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|l|p{5cm}|}
    \hline
      \textbf{Playing Styles} & \textbf{Description} \\
      \hline
      Tight & Plays few hands and often folds. \\
      \hline
      Loose & Plays multiple and varied hands.  \\
      \hline
      Aggressive &  Bets and raises a lot, almost always never checking or call. \\
      \hline
      Passive & Usually checks and call, unlikely to take the lead. \\
      \hline
    \end{tabular}
    \caption{Description of Playing Styles}
    \label{tab:table3}
  \end{center}
\end{table}
The Aggressive Factor, $AF$, is used to classify a player as either Aggressive or Passive. The formula for $AF$ is as follows:
\begin{displaymath}
  AF = \frac{\text{\# }raises}{\text{\# }calls}
\end{displaymath}
\noindent Players can be classified into either Aggressive or Passive by the percentage of games they have played. Based on research by Rupeneite~\shortcite{rupeneite:Reinforcement}, a threshold of 1 is used:
\begin{itemize}
	\item Aggressive if $AF > 1$
	\item Passive if $AF \leq 1$
\end{itemize}

The Player Tightness, $PT$, is used to classify a player as either Loose or Tight. The formula for $PT$ is as follows:
\begin{displaymath}
  PT =  \frac{\text{\# }folds}{\text{\# }games} 
\end{displaymath}
\noindent Players can be classified into either Loose or Tight by the percentage of games they have played. Based on research by Rupeneite~\shortcite{rupeneite:Reinforcement}, a threshold of 0.28 is used:
\begin{itemize}
	\item Tight if $PT < 0.28$ hands
	\item Loose if $PT \geq 0.28$ hands
\end{itemize}

Later, a classification process, introduced by Dinis and Reis~\shortcite{dinis-reis:modeling}, is conducted to classify the opponent's style of play into four categories, as seen in Table 4.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{p{1.5cm}|p{2cm}|p{2cm}}
      \textbf{} & \textbf{AF $\leq$ 1} & \textbf{AF $>$ 1} \\
      \hline
      \textbf{PT $\geq$ 0.28} & Loose \newline Passive & Loose \newline Aggressive \\
      \hline
      \textbf{PT $<$ 0.28} & Tight \newline Passive & Tight \newline Aggressive \\
    \end{tabular}
    \caption{Style of Play Classification}
    \label{tab:table4}
  \end{center}
\end{table}

\iffalse
\section{Hand Potential}

Hand Potential is an extension of the Hand Strength algorithm, whereby instead of merely considering the available cards in hand and in the community pool, it also considers the as yet unrevealed community cards and possible opponent hands that might improve. In the River street, this algorithm will output the same result as Hand Strength.

Hand Potential can be split into Positive Potential, $PPot$ and Negative Potential $NPot$, which are defined as such:
\begin{description}[style=multiline,leftmargin=10mm]
\item [\emph{PPot}]All scenarios where the agent is behind but eventually wins.
\item [\emph{NPot}]All scenarios where the agent is ahead but eventually loses.
\end{description}

The algorithm for Hand Potential is described in detail via pseudo-code in Algorithm 1.

  \begin{algorithm}
   \caption{Hand Potential}
    \begin{algorithmic}[1]
      \Function{HandPotential}{$agCard$, $commCard$}              
        \State Let $HP[3][3]$ and $HPTotal[3]$ be new arrays
        \State $agRank \leftarrow Rank(agCard$, $commCard)$
        \For{\textbf{each} $opCard$}
            \State $opRank \leftarrow Rank(opCard$, $commCard)$
            \If{$agRank > opRank$}
              \State $index \leftarrow ahead$
            \ElsIf{$agRank == opRank$}
              \State $index \leftarrow tied$
            \Else
              \State $index \leftarrow behind$
            \EndIf
            \State $HPTotal[index]++$
            \For{\textbf{each} $scenario$}
              \State $agBest \leftarrow Rank(agCard, scenario)$
              \State $opBest \leftarrow Rank(opCard, scenario)$
              \If{$agBest > opBest$}
                \State $HP[index][ahead]++$
              \ElsIf{$agBest == opBest$}
                \State $HP[index][tied]++$
              \Else
                \State $HP[index][behind]++$
              \EndIf
            \EndFor
        \EndFor
        \State $PPot=\frac{HP[behind][ahead] + \frac{HP[behind][tied]}{2} +
  \frac{HP[tied][ahead]}{2})}{HPTotal[behind]+\frac{HPTotal[tied]}{2}}$
		\State $NPot = \frac{HP[ahead][behind] + \frac{HP[tied][behind]}{2} + \frac{HP[ahead][tied]}{2}}{HPTotal[ahead]+\frac{HPTotal[tied]}{2}}$
        \State\Return{$PPot$, $NPot$}
      \EndFunction
    \end{algorithmic}
  \end{algorithm}

\section{Effective Hand Strength}
The probability of winning, $Pr(Win)$, can be calculated as:
\begin{displaymath}
  Pr(Win) = HS * (1-NPot) + (1-HS) * PPot
\end{displaymath}
To calculate $EHS$, we set $NPot=0$ since we want the probability of the hand being the best or improving to become the best. Thus, we eventually get the equation of $EHS$ to be:
\begin{displaymath}
  EHS = HS +(1-HS) * PPot
\end{displaymath}

\subsection{Word Processing Software}

As detailed below, IJCAI has prepared and made available a set of
\LaTeX{} macros and a Microsoft Word template for use in formatting
your paper. If you are using some other word processing software (such
as WordPerfect, etc.), please follow the format instructions given
below and ensure that your final paper looks as much like this sample
as possible.

{\bf Note that I did not edit the word document, and it still contains the original IJCAI formatting instructions. Please ignore those!}

\section{Style and Format}

\LaTeX{} and Word style files that implement these instructions
can be retrieved electronically. (See Appendix~\ref{stylefiles} for
instructions on how to obtain these files.)

\subsection{Layout}

Print manuscripts two columns to a page, in the manner in which these
instructions are printed. The exact dimensions for pages are:
\begin{itemize}
\item left and right margins: .75$''$
\item column width: 3.375$''$
\item gap between columns: .25$''$
\item top margin---first page: 1.375$''$
\item top margin---other pages: .75$''$
\item bottom margin: 1.25$''$
\item column height---first page: 6.625$''$
\item column height---other pages: 9$''$
\end{itemize}

All measurements assume an 8-1/2$''$ $\times$ 11$''$ page size. For
A4-size paper, use the given top and left margins, column width,
height, and gap, and modify the bottom and right margins as necessary.

\subsection{Format of Electronic Manuscript}

For the production of the electronic manuscript, you must use Adobe's
{\em Portable Document Format} (PDF). A PDF file can be generated, for
instance, on Unix systems using {\tt ps2pdf} or on Windows systems
using Adobe's Distiller. There is also a website with free software
and conversion services: {\tt http://www.ps2pdf.com/}. For reasons of
uniformity, use of Adobe's {\em Times Roman} font is strongly suggested. In
\LaTeX2e{}, this is accomplished by putting
\begin{quote} 
\mbox{\tt $\backslash$usepackage\{times\}}
\end{quote}
in the preamble.\footnote{You may want also to use the package {\tt
latexsym}, which defines all symbols known from the old \LaTeX{}
version.}
  
Additionally, it is of utmost importance to specify the American {\bf
letter} format (corresponding to 8-1/2$''$ $\times$ 11$''$) when
formatting the paper. When working with {\tt dvips}, for instance, one
should specify {\tt -t letter}.

\subsection{Title and Author Information}

Center the title on the entire width of the page in a 14-point bold
font. The title should be capitalized using Title Case. Below it, center author name(s) in a 12-point bold font. On the following line(s) place the affiliations, each affiliation on its own line using a 12-point regular font. Matching between authors and affiliations can be done using superindices. Additionally, a comma-separated email addresses list using a 12-point regular font is also allowed. Credit to a
sponsoring agency can appear on the first page as a footnote.

\subsection{Text}

The main body of the text immediately follows the abstract. Use
10-point type in a clear, readable font with 1-point leading (10 on
11).

Indent when starting a new paragraph, except after major headings.

\subsection{Headings and Sections}

When necessary, headings should be used to separate major sections of
your paper. (These instructions use many headings to demonstrate their
appearance; your paper should have fewer headings.). All headings should be capitalized using Title Case.

\subsubsection{Section Headings}

Print section headings in 12-point bold type in the style shown in
these instructions. Leave a blank space of approximately 10 points
above and 4 points below section headings.  Number sections with
arabic numerals.

\subsubsection{Subsection Headings}

Print subsection headings in 11-point bold type. Leave a blank space
of approximately 8 points above and 3 points below subsection
headings. Number subsections with the section number and the
subsection number (in arabic numerals) separated by a
period.

\subsubsection{Subsubsection Headings}

Print subsubsection headings in 10-point bold type. Leave a blank
space of approximately 6 points above subsubsection headings. Do not
number subsubsections.

\subsubsection{Special Sections}

You may include an unnumbered acknowledgments section, including
acknowledgments of help from colleagues.

Any appendices directly follow the text and look like sections, except
that they are numbered with capital letters instead of arabic
numerals.

The references section is headed ``References,'' printed in the same
style as a section heading but without a number~\cite{russell-norvig:Modern}. A sample list of
references is given at the end of these instructions~\cite{rupeneite:Reinforcement}. Use a consistent
format for references, such as that provided by Bib\TeX{}. The reference
list should not include unpublished work~\cite{trc:hs}.

\subsection{Citations}

Citations within the text should include the author's last name and
the year of publication, for example~\cite{trc:ars}.  Append
lowercase letters to the year in cases of ambiguity.  Treat multiple
authors as in the following examples:
or (for more than two authors) and (for two authors).  If the author
portion of a citation is obvious, omit it, e.g.,
Nebel.  Collapse multiple citations as
follows:
~\cite{trc:ars}
~\cite{trc:hs}
~\cite{rupeneite:Reinforcement}
~\cite{russell-norvig:Modern}
~\cite{sqas:replay}

\subsection{Footnotes}

Place footnotes at the bottom of the page in a 9-point font.  Refer to
them with superscript numbers.\footnote{This is how your footnotes
should appear.} Separate them from the text by a short
line.\footnote{Note the line separating these footnotes from the
text.} Avoid footnotes as much as possible; they interrupt the flow of
the text.

\section{Illustrations}

Place all illustrations (figures, drawings, tables, and photographs)
throughout the paper at the places where they are first discussed,
rather than at the end of the paper. If placed at the bottom or top of
a page, illustrations may run across both columns.

Illustrations must be rendered electronically or scanned and placed
directly in your document. All illustrations should be in black and
white, as color illustrations may cause problems. Line weights should
be 1/2-point or thicker. Avoid screens and superimposing type on
patterns as these effects may not reproduce well.

Number illustrations sequentially. Use references of the following
form: Figure 1, Table 2, etc. Place illustration numbers and captions
under illustrations. Leave a margin of 1/4-inch around the area
covered by the illustration and caption.  Use 9-point type for
captions, labels, and other text in illustrations.
\fi

\section*{Acknowledgments}

The preparation of this report would not have been possible without the help of Dr. Yair Zick and Arka Maity, National University of Singapore, School of Computing.

\appendix

\iffalse
\section{\LaTeX{} and Word Style Files}\label{stylefiles}

The \LaTeX{} and Word style files are available on the IJCAI--18
website, {\tt http://www.ijcai-18.org/}.
These style files implement the formatting instructions in this
document.

The \LaTeX{} files are {\tt ijcai18.sty} and {\tt ijcai18.tex}, and
the Bib\TeX{} files are {\tt named.bst} and {\tt ijcai18.bib}. The
\LaTeX{} style file is for version 2e of \LaTeX{}, and the Bib\TeX{}
style file is for version 0.99c of Bib\TeX{} ({\em not} version
0.98i). The {\tt ijcai18.sty} file is the same as the {\tt
ijcai07.sty} file used for IJCAI--07.

The Microsoft Word style file consists of a single file, {\tt
ijcai18.doc}. This template is the same as the one used for
IJCAI--07.

These Microsoft Word and \LaTeX{} files contain the source of the
present document and may serve as a formatting sample.  
\fi

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{reportLatest}

\end{document}

