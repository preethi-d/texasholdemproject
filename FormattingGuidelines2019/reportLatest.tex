%%%% ijcai18.tex

\typeout{IJCAI-18 Instructions for Authors}

% These are the instructions for authors for IJCAI-18.
% They are the same as the ones for IJCAI-11 with superficical wording
%   changes only.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai18.sty is the style file for IJCAI-18 (same as ijcai08.sty).
\usepackage{ijcai18}

% Use the postscript times font!
\usepackage{mathptmx}
\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}


% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Poker Project - Team 07}


% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)

\author{
Arielyte Tsen Chung Ming, Devarajan Preethi, James Pang Mun Wai, Lee Yi Wei Joel, Yip Seng Yuen
\\ 
National University of Singapore\\
%
chungming.tsen@u.nus.edu, e0203237@u.nus.edu, jamespang@nus.edu, lywjoel@u.nus.edu, yip@u.nus.edu
}
% If your authors do not fit in the default space, you can increase it 
% by uncommenting the following (adjust the "2.5in" size to make it fit
% properly)
% \setlength\titlebox{2.5in}

\begin{document}

\maketitle

\section{Introduction}

The game of poker has long been a field of interest for artificial intelligence (AI) researchers. There are many challenges with developing an AI poker agent capable of competing with humans, since poker is a complex game that forces players to make decisions with incomplete and imperfect information. AI poker agents are hence faced with the task of having to make the best decision at every street under such informational constraints. Additionally, conventional poker matches impose a time limit on players to make a decision, adding another constraint for AI poker agents to work with.

This paper outlines our design of an AI poker agent for Heads Up Limit Texas Hold’em, which aims to respond competently and accurately with limited information, within a limited amount of time. In tackling the issues above, we employed a three-pronged approach:

\begin{itemize}
  \item Using Q-learning, a reinforcement learning algorithm, to train our agent to play with the best possible strategy. (Section 3.1)
  \item Reduce the overall state size, by grouping similar states together. (Section 3.1, Abstraction of States)
  \item Precomputing the estimated strength of hand ranks, storing them in look-up tables to allow for retrieval in constant time. (Section 3.3)
 \end{itemize}

The following two sections will explain our agent’s strategy within each betting round, namely the pre-flop and post-flop streets.
\section{Preflop Street}

In order to decide what action the agent would take based only on the limited amount of information it has during the preflop street, we introduce the use of hand strength ($HS$), which is an estimate determined by the probability of winning with the two hole cards currently in the agent’s hand.
To estimate $HS$, we perform a Monte Carlo simulation of 10,000 games for each possible starting hand. The total number of possible starting hands is 91, which is obtained by summing up the total number of possible pocket pairs and the total number of possible hands disregarding the suits. For each game, we first pick the two starting cards for the agent, followed by randomly picking two starting cards for the opponent and the five community cards. Both players’ hands are then revealed and the game result is determined as a win or a loss for the agent.

We then calculate $HS$ using the formula:
\begin{displaymath}
 HS = Pr(Win)= \frac{\# \text{ } of \text{ } wins}{Total \text{ }games \text{ } played}
\end{displaymath}
Where the total games played is fixed at 10,000. The results of the Monte Carlo simulation are seen in Figure \ref{fig:1}.
\begin{figure}
  \includegraphics[width=\linewidth]{WinningProb.PNG}
  \caption{Estimated winning probabilities with starting hands}
  \label{fig:1}
\end{figure}

At every preflop street, the agent chooses an action [fold, call, raise] to take based on the $HS$ of the starting hand:
\begin{displaymath}
  \left.
  \begin{array}{l}
    raise \text{: } HS > k \\
    \\
    call \text{: } HS > j \\
    \\
    fold \text{: } HS \leq j
  \end{array}
  \right\rbrace \quad \text{where } 0 < j < k \leq 1
\end{displaymath}
Where $j$ and $k$ are pre-determined thresholds set for the agent.

\section{Postflop Streets}
The postflop streets consist of Flop, Turn and River. As compared to preflop street, at least three community cards are revealed, giving us more information to work with. During the postflop rounds, reinforcement learning is employed. Specifically, we use a modified version of Q-learning to train our agent.

\subsection{Q-learning}

In Q-learning, we maintain a table of states and actions as input for the agent. Each state has a Q-value that corresponds to each action. The Q-value signifies the expected reward at that state. An illustration of the Q-learning table can be seen in Table 1.

\begin{table}[h!]
  \begin{center}
	\begin{tabular}{ c|c|c|c }
	\hline
	\multirow{2}{*}{\textbf{State}}&\multicolumn{3}{|c}{\textbf{Action}}\\
	\cline{2-4}
	& $fold$ & $call$ & $raise$\\ 
	\hline
	1\\
	2\\ 
	3\\ 
	$\cdots$\\
	S\\
	\hline
	\end{tabular}
	\caption{Q-learning Training}
    \label{tab:table1}
  \end{center}
\end{table}
The reward function is determined based on the pot size P - the total amount that has been bet so far - at the end of the game, as seen in the formula below:
\begin{displaymath}
  R_t=
  \left\lbrace
  \begin{array}{l}
    +\frac{P}{2}\quad\text{if win,} \\
    \\
    -\frac{P}{2}\quad\text{otherwise}
  \end{array}
  \right.
\end{displaymath}

After each training round, the Q-value of each state is obtained by summing up the previous Q-value and the reward function for that round. More formally,
\begin{displaymath}
Q\left(s',a'\right)=Q\left(s,a\right)+\sum_{0}^{t}\lambda^{t}R_t\left(s,a\right)
\end{displaymath}
\noindent Where $t$ is the number of turns between the current move and the terminal node, $R_t$ is the reward for round $t$, $\lambda$ is the discount factor, $s$ is the state, $a$ is the action and $P$ is the pot size.

\subsubsection{Experience Replay}
Additionally, we apply the technique of experience replay to achieve more efficient use of previous experiences. We store the agent's experiences based on the formula
\begin{displaymath}
e_t=\left(s_t,a_t,R_t,s_{t+1}\right)
\end{displaymath}
The agent stores the data it discovers for each round in a table, and reinforcement learning takes place based on random sampling from the table. This reduces the amount of experience required to learn, replacing it with more computation and memory which are cheaper resources than the agent's continuous interactions with the environment~\cite{sqas:replay}.

\subsubsection{$\epsilon$-Greedy Algorithm}

At every turn, with a probability of $\epsilon$, a random action is chosen to be performed, otherwise an action with the best expected reward (highest Q-value) is chosen.

The value of $\epsilon$ will slowly decrease as the agent acquires more training. A relatively large initial value ensures that all possible paths will be explored before the agent settles into a sub-optimal pattern. The $i$-th $State$ and possible $Actions$ for the $\epsilon$-Greedy Algorithm is
\begin{displaymath}
State_i = \{ EHS_i \text{, } S_i \text{, }P_i\text{, }\#OR_i\text{, }\#SR_i\text{, }OPS_i\}
\end{displaymath}
\begin{displaymath}
Actions = \{ fold\text{, }call\text{, }raise \}
\end{displaymath}
Where

\begin{description}[style=multiline,leftmargin=10mm]
\item [\emph{EHS}]refers to the current Expected Hand Strength of a given player. More details can be found in Section 3.2.
\item [\emph{S}]refers to the current Street of the round.
\item [\emph{P}]refers to the Pot Size.
\item [\emph{\#OR}]refers to the number of Opponent Raises per street.
\item [\emph{\#SR}]refers to the number of Self Raises per street.
\item [\emph{OPS}]refers to the Opponent Playing Style.
\end{description}

\subsubsection{Abstraction of States}
Without abstracting the states into groups, the total size of the state space will be very large and it would be infeasible to calculate all possible states. Therefore, we can apply abstraction by grouping some of the features in increments.
\begin{itemize}
  \item $EHS$ is grouped in increments of 0.01, from 0 to 1.
  \item There are three streets - Flop, Turn and River.
  \item $P$ in a game ranges from \$0 to \$680, but by grouping it in increments of \$40, which is the 2 times big blind amount, since every raise (big blind amount - \$20) must minimally be matched by the opponent, we get a range of 0 to 17.
  \item $\#OR$ is grouped into five different groups, i.e. from 0 to 4.
  \item $\#SR$ is grouped into five different groups, i.e. from 0 to 4.
  \item $OPS$ is grouped into four categories. More details can be found in Section 3.4.
\end{itemize}

These groupings help to reduce the complexity and cut down the size of the total state space to: $101 \times 3 \times 18 \times 5 \times 5 \times 4 = 545,400$ states


\subsection{Expected Hand Strength}

The Expected Hand Strength, $EHS$, is the probability of the current hand of a given player winning if the game reaches a showdown. It factors in all possible combinations of what the opponent's hand could be and the remaining hidden board cards, and compares each of these hands to the agent's hand, to see which is better. The $EHS$ of the agent's hand is then calculated, by finding the number of times that particular hand turns out to be better than the opponent's. We do this by comparing the number of comparisons in which the agent had a better hand, to the total number of comparisons. More formally,
\begin{displaymath}
  EHS(h)= \frac{Ahead(h)+\frac{Tied(h)}{2}}{Ahead(h) + Tied(h) + Behind(h)}
\end{displaymath}

\noindent Where $Ahead$, $Tied$, and $Behind$ functions determine respectively the number of times the player's hand wins, ties or loses the game. The above formula used to derive the $EHS$ was referenced from Teofilo \textit{et al.}~\shortcite{trc:hs}. 

Note that the $EHS$ may be used at any round of the game. However, the time required to compute an accurate EHS exceeds the time constraint of 0.2s set by the project guidelines, as the number of iterations needed to compute it for a single hand at the pre-flop street is very high. This issue is addressed using look-up tables, which is explained in the next section.

\subsection{EHS Look-up Table}

We devised a technique similar to Average Rank Strength ($ARS$) ~\cite{trc:ars} to improve the efficiency of $EHS$. In our method, three look-up tables are created - one for Flop, one for Turn and one for River. These tables consist of precomputed $EHS$ values for all possible scores. The score value for a particular set of cards refers to the strength of the current hand ranking, and is computed using PyPokerEngine's built-in $HandEvaluator.eval()$ function. For example, given some combination of hole cards and community cards which contain a Pair ranking, $HandEvaluator.eval()$ returns a numeric representation of this hand ranking, which would be lower than if there were a Three-of-a-Kind ranking. 

Instead of computing $EHS$ during gameplay, the agent can now simply refer to the look-up table, based on its current score, to obtain its $EHS$. This technique runs in constant time, and responds 1000 times faster with negligible error~\cite{trc:ars}.

To estimate the $EHS$ for the three post-flop streets, we simulated 2.5 million rounds each. Additionally, for each round of simulation, we ran the Monte Carlo sampling algorithm 500 times to obtain the $EHS$. The results are displayed below:

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|c}
      \textbf{Street} & \textbf{Number of Distinct Scores} \\
      \hline
      Flop & 5133 \\
      Turn & 13,408 \\
      River & 17,470 \\
    \end{tabular}
    \caption{Result of $EHS$ Look-up Tables Simulation}
    \label{tab:table2}
  \end{center}
\end{table}

\noindent We are aware that not all possible scores may have been captured in the tables generated during the 2.5 million rounds. However, despite this, the results from simulating 100,000 games show that approximately 99.87 percent of the scores can be found in the table. This goes to show that our three look-up tables are highly reliable.

\subsection{Opponent Playing Styles}

According to Rupeneite~\shortcite{rupeneite:Reinforcement}, the playing style of an opponent can be classified into four categories. Each style is distinct, in that it describes the opponent's frequency of play and how the player bets. The four categories of playing styles are Loose/Passive, Loose/Aggressive, Tight/Passive and Tight/Aggressive. A brief description of each style is shown in Table 3 below:

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{|l|p{5cm}|}
    \hline
      \textbf{Playing Styles} & \textbf{Description} \\
      \hline
      Tight & Plays few hands and often folds. \\
      \hline
      Loose & Plays multiple and varied hands.  \\
      \hline
      Aggressive &  Bets and raises a lot, almost always never checking or call. \\
      \hline
      Passive & Usually checks and call, unlikely to take the lead. \\
      \hline
    \end{tabular}
    \caption{Description of Playing Styles}
    \label{tab:table3}
  \end{center}
\end{table}
The Aggressive Factor, $AF$, is used to classify a player as either Aggressive or Passive. The formula for $AF$ is as follows:
\begin{displaymath}
  AF = \frac{\text{\# }raises}{\text{\# }calls}
\end{displaymath}
\noindent Players can be classified into either Aggressive or Passive by the percentage of games they have played. Based on research by Rupeneite~\shortcite{rupeneite:Reinforcement}, a threshold of 1 is used:
\begin{itemize}
	\item Aggressive if $AF > 1$
	\item Passive if $AF \leq 1$
\end{itemize}

The Player Tightness, $PT$, is used to classify a player as either Loose or Tight. The formula for $PT$ is as follows:
\begin{displaymath}
  PT =  \frac{\text{\# }folds}{\text{\# }games} 
\end{displaymath}
\noindent Players can be classified into either Loose or Tight by the percentage of games they have played. Based on research by Rupeneite~\shortcite{rupeneite:Reinforcement}, a threshold of 0.28 is used:
\begin{itemize}
	\item Tight if $PT < 0.28$ hands
	\item Loose if $PT \geq 0.28$ hands
\end{itemize}

Later, a classification process, introduced by Dinis and Reis~\shortcite{dinis-reis:modeling}, is conducted to classify the opponent's style of play into four categories, as seen in Table 4.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{p{1.5cm}|p{2cm}|p{2cm}}
      \textbf{} & \textbf{AF $\leq$ 1} & \textbf{AF $>$ 1} \\
      \hline
      \textbf{PT $\geq$ 0.28} & Loose \newline Passive & Loose \newline Aggressive \\
      \hline
      \textbf{PT $<$ 0.28} & Tight \newline Passive & Tight \newline Aggressive \\
    \end{tabular}
    \caption{Style of Play Classification}
    \label{tab:table4}
  \end{center}
\end{table}

\section{Limitations}

\subsection{Q-values converging}
The Q-value refers to the expected reward at every state of the game. As mentioned in the $\epsilon$-Greedy algorithm, at every turn there is a probability of $\epsilon$ that a random action is chosen, else the action with the highest Q-value is chosen. A Q-value that is reliable is one that converges, meaning multiple occurrences of that particular state returned Q-values that did not vary too much from each other. Ideally, we would want to allow the agent to learn until all Q-values converge, which would allow the agent to choose the best action at every state. However, due to the time constraints of the project, our agent did not receive sufficient training and hence has Q-values that do not converge. This means that it is not guaranteed that our agent will always be able to take the best action, due to the inaccuracy of some of the Q-values.

\subsection{Counterfactual Regret Minimisation}
Counterfactual Regret Minimisation (CFR) is another reinforcement learning algorithm that we could have used while implementing our poker agent. This is an algorithm that seeks to minimise regret about its decisions at each step of a game. There are two types of regret - positive and negative regret. Negative regret refers to the regret of having taken a particular action in a particular situation. It means the agent would have done better had it not chosen this action in this situation. Positive regret is mechanism by which the agent tracks actions that resulted in a positive outcome. Unlike Q-learning, which remembers the reward received for every action and chooses the action with the highest reward, CFR remembers the regret for every action and favours the action it regretted not having taken previously. However, CFR assumes that a terminal state is eventually reached and performs updates only after this occurs, which is not a requirement for traditional algorithms like Q-learning.

\iffalse
\section{Hand Potential}

Hand Potential is an extension of the Hand Strength algorithm, whereby instead of merely considering the available cards in hand and in the community pool, it also considers the as yet unrevealed community cards and possible opponent hands that might improve. In the River street, this algorithm will output the same result as Hand Strength.

Hand Potential can be split into Positive Potential, $PPot$ and Negative Potential $NPot$, which are defined as such:
\begin{description}[style=multiline,leftmargin=10mm]
\item [\emph{PPot}]All scenarios where the agent is behind but eventually wins.
\item [\emph{NPot}]All scenarios where the agent is ahead but eventually loses.
\end{description}

The algorithm for Hand Potential is described in detail via pseudo-code in Algorithm 1.

  \begin{algorithm}
   \caption{Hand Potential}
    \begin{algorithmic}[1]
      \Function{HandPotential}{$agCard$, $commCard$}              
        \State Let $HP[3][3]$ and $HPTotal[3]$ be new arrays
        \State $agRank \leftarrow Rank(agCard$, $commCard)$
        \For{\textbf{each} $opCard$}
            \State $opRank \leftarrow Rank(opCard$, $commCard)$
            \If{$agRank > opRank$}
              \State $index \leftarrow ahead$
            \ElsIf{$agRank == opRank$}
              \State $index \leftarrow tied$
            \Else
              \State $index \leftarrow behind$
            \EndIf
            \State $HPTotal[index]++$
            \For{\textbf{each} $scenario$}
              \State $agBest \leftarrow Rank(agCard, scenario)$
              \State $opBest \leftarrow Rank(opCard, scenario)$
              \If{$agBest > opBest$}
                \State $HP[index][ahead]++$
              \ElsIf{$agBest == opBest$}
                \State $HP[index][tied]++$
              \Else
                \State $HP[index][behind]++$
              \EndIf
            \EndFor
        \EndFor
        \State $PPot=\frac{HP[behind][ahead] + \frac{HP[behind][tied]}{2} +
  \frac{HP[tied][ahead]}{2})}{HPTotal[behind]+\frac{HPTotal[tied]}{2}}$
		\State $NPot = \frac{HP[ahead][behind] + \frac{HP[tied][behind]}{2} + \frac{HP[ahead][tied]}{2}}{HPTotal[ahead]+\frac{HPTotal[tied]}{2}}$
        \State\Return{$PPot$, $NPot$}
      \EndFunction
    \end{algorithmic}
  \end{algorithm}

\section{Effective Hand Strength}
The probability of winning, $Pr(Win)$, can be calculated as:
\begin{displaymath}
  Pr(Win) = HS * (1-NPot) + (1-HS) * PPot
\end{displaymath}
To calculate $EHS$, we set $NPot=0$ since we want the probability of the hand being the best or improving to become the best. Thus, we eventually get the equation of $EHS$ to be:
\begin{displaymath}
  EHS = HS +(1-HS) * PPot
\end{displaymath}

\subsection{Word Processing Software}

As detailed below, IJCAI has prepared and made available a set of
\LaTeX{} macros and a Microsoft Word template for use in formatting
your paper. If you are using some other word processing software (such
as WordPerfect, etc.), please follow the format instructions given
below and ensure that your final paper looks as much like this sample
as possible.

{\bf Note that I did not edit the word document, and it still contains the original IJCAI formatting instructions. Please ignore those!}

\section{Style and Format}

\LaTeX{} and Word style files that implement these instructions
can be retrieved electronically. (See Appendix~\ref{stylefiles} for
instructions on how to obtain these files.)

\subsection{Layout}

Print manuscripts two columns to a page, in the manner in which these
instructions are printed. The exact dimensions for pages are:
\begin{itemize}
\item left and right margins: .75$''$
\item column width: 3.375$''$
\item gap between columns: .25$''$
\item top margin---first page: 1.375$''$
\item top margin---other pages: .75$''$
\item bottom margin: 1.25$''$
\item column height---first page: 6.625$''$
\item column height---other pages: 9$''$
\end{itemize}

All measurements assume an 8-1/2$''$ $\times$ 11$''$ page size. For
A4-size paper, use the given top and left margins, column width,
height, and gap, and modify the bottom and right margins as necessary.

\subsection{Format of Electronic Manuscript}

For the production of the electronic manuscript, you must use Adobe's
{\em Portable Document Format} (PDF). A PDF file can be generated, for
instance, on Unix systems using {\tt ps2pdf} or on Windows systems
using Adobe's Distiller. There is also a website with free software
and conversion services: {\tt http://www.ps2pdf.com/}. For reasons of
uniformity, use of Adobe's {\em Times Roman} font is strongly suggested. In
\LaTeX2e{}, this is accomplished by putting
\begin{quote} 
\mbox{\tt $\backslash$usepackage\{times\}}
\end{quote}
in the preamble.\footnote{You may want also to use the package {\tt
latexsym}, which defines all symbols known from the old \LaTeX{}
version.}
  
Additionally, it is of utmost importance to specify the American {\bf
letter} format (corresponding to 8-1/2$''$ $\times$ 11$''$) when
formatting the paper. When working with {\tt dvips}, for instance, one
should specify {\tt -t letter}.

\subsection{Title and Author Information}

Center the title on the entire width of the page in a 14-point bold
font. The title should be capitalized using Title Case. Below it, center author name(s) in a 12-point bold font. On the following line(s) place the affiliations, each affiliation on its own line using a 12-point regular font. Matching between authors and affiliations can be done using superindices. Additionally, a comma-separated email addresses list using a 12-point regular font is also allowed. Credit to a
sponsoring agency can appear on the first page as a footnote.

\subsection{Text}

The main body of the text immediately follows the abstract. Use
10-point type in a clear, readable font with 1-point leading (10 on
11).

Indent when starting a new paragraph, except after major headings.

\subsection{Headings and Sections}

When necessary, headings should be used to separate major sections of
your paper. (These instructions use many headings to demonstrate their
appearance; your paper should have fewer headings.). All headings should be capitalized using Title Case.

\subsubsection{Section Headings}

Print section headings in 12-point bold type in the style shown in
these instructions. Leave a blank space of approximately 10 points
above and 4 points below section headings.  Number sections with
arabic numerals.

\subsubsection{Subsection Headings}

Print subsection headings in 11-point bold type. Leave a blank space
of approximately 8 points above and 3 points below subsection
headings. Number subsections with the section number and the
subsection number (in arabic numerals) separated by a
period.

\subsubsection{Subsubsection Headings}

Print subsubsection headings in 10-point bold type. Leave a blank
space of approximately 6 points above subsubsection headings. Do not
number subsubsections.

\subsubsection{Special Sections}

You may include an unnumbered acknowledgments section, including
acknowledgments of help from colleagues.

Any appendices directly follow the text and look like sections, except
that they are numbered with capital letters instead of arabic
numerals.

The references section is headed ``References,'' printed in the same
style as a section heading but without a number~\cite{russell-norvig:Modern}. A sample list of
references is given at the end of these instructions~\cite{rupeneite:Reinforcement}. Use a consistent
format for references, such as that provided by Bib\TeX{}. The reference
list should not include unpublished work~\cite{trc:hs}.

\subsection{Citations}

Citations within the text should include the author's last name and
the year of publication, for example~\cite{trc:ars}.  Append
lowercase letters to the year in cases of ambiguity.  Treat multiple
authors as in the following examples:
or (for more than two authors) and (for two authors).  If the author
portion of a citation is obvious, omit it, e.g.,
Nebel.  Collapse multiple citations as
follows:
~\cite{trc:ars}
~\cite{trc:hs}
~\cite{rupeneite:Reinforcement}
~\cite{russell-norvig:Modern}
~\cite{sqas:replay}

\subsection{Footnotes}

Place footnotes at the bottom of the page in a 9-point font.  Refer to
them with superscript numbers.\footnote{This is how your footnotes
should appear.} Separate them from the text by a short
line.\footnote{Note the line separating these footnotes from the
text.} Avoid footnotes as much as possible; they interrupt the flow of
the text.

\section{Illustrations}

Place all illustrations (figures, drawings, tables, and photographs)
throughout the paper at the places where they are first discussed,
rather than at the end of the paper. If placed at the bottom or top of
a page, illustrations may run across both columns.

Illustrations must be rendered electronically or scanned and placed
directly in your document. All illustrations should be in black and
white, as color illustrations may cause problems. Line weights should
be 1/2-point or thicker. Avoid screens and superimposing type on
patterns as these effects may not reproduce well.

Number illustrations sequentially. Use references of the following
form: Figure 1, Table 2, etc. Place illustration numbers and captions
under illustrations. Leave a margin of 1/4-inch around the area
covered by the illustration and caption.  Use 9-point type for
captions, labels, and other text in illustrations.
\fi

\section*{Acknowledgments}

The preparation of this report would not have been possible without the help of Dr. Yair Zick and Arka Maity, National University of Singapore, School of Computing.

\appendix

\iffalse
\section{\LaTeX{} and Word Style Files}\label{stylefiles}

The \LaTeX{} and Word style files are available on the IJCAI--18
website, {\tt http://www.ijcai-18.org/}.
These style files implement the formatting instructions in this
document.

The \LaTeX{} files are {\tt ijcai18.sty} and {\tt ijcai18.tex}, and
the Bib\TeX{} files are {\tt named.bst} and {\tt ijcai18.bib}. The
\LaTeX{} style file is for version 2e of \LaTeX{}, and the Bib\TeX{}
style file is for version 0.99c of Bib\TeX{} ({\em not} version
0.98i). The {\tt ijcai18.sty} file is the same as the {\tt
ijcai07.sty} file used for IJCAI--07.

The Microsoft Word style file consists of a single file, {\tt
ijcai18.doc}. This template is the same as the one used for
IJCAI--07.

These Microsoft Word and \LaTeX{} files contain the source of the
present document and may serve as a formatting sample.  
\fi

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{reportLatest}

\end{document}

